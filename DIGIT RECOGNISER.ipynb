{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6f1502c",
   "metadata": {},
   "source": [
    "# Implementation of Digital Recogniser with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7fac13",
   "metadata": {},
   "source": [
    "### Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "007ab243",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056e4c9",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f1ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    "    \n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88331552",
   "metadata": {},
   "source": [
    "### Check for total datapoints in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f93f766f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training data:\n",
      "---------------------\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "\n",
      "Total testing data:\n",
      "---------------------\n",
      " Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print('Total training data:\\n---------------------\\n {}\\n\\nTotal testing data:\\n---------------------\\n {}'.format(train_data, test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e430c4f9",
   "metadata": {},
   "source": [
    "### Check for the classes for both training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f37167f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0 - zero': 0,\n",
       " '1 - one': 1,\n",
       " '2 - two': 2,\n",
       " '3 - three': 3,\n",
       " '4 - four': 4,\n",
       " '5 - five': 5,\n",
       " '6 - six': 6,\n",
       " '7 - seven': 7,\n",
       " '8 - eight': 8,\n",
       " '9 - nine': 9}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab3cb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4,  ..., 5, 6, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb81def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - zero\n",
      "1 - one\n",
      "2 - two\n",
      "3 - three\n",
      "4 - four\n",
      "5 - five\n",
      "6 - six\n",
      "7 - seven\n",
      "8 - eight\n",
      "9 - nine\n"
     ]
    }
   ],
   "source": [
    "for j in train_data.classes:\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426d4d94",
   "metadata": {},
   "source": [
    "### Check for tensor image data and its shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d290a56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total image for the testing data: 10000\n",
      "Height of the image: 28\n",
      "Width of the image: 28\n"
     ]
    }
   ],
   "source": [
    "test_data.data.shape\n",
    "print('The total image for the testing data: {}\\nHeight of the image: {}\\nWidth of the image: {}'.format(test_data.data.shape[0], test_data.data.shape[1],test_data.data.size()[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7164c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total image for the testing data: 60000\n",
      "Height of the image: 28\n",
      "Width of the image: 28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]],\n",
       " \n",
       "         [[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape\n",
    "print('The total image for the testing data: {}\\nHeight of the image: {}\\nWidth of the image: {}'.format(train_data.data.shape[0], train_data.data.shape[1],train_data.data.size()[2])), train_data.data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317c1d58",
   "metadata": {},
   "source": [
    "### Load the data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3e8bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': DataLoader(train_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1),\n",
    "    \n",
    "    'test': DataLoader(test_data,\n",
    "                        batch_size=100,\n",
    "                        shuffle=True,\n",
    "                        num_workers=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79dcc511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x25c9026bed0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x25c90248590>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ecb84f",
   "metadata": {},
   "source": [
    "### Create the class model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14901c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitalCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitalCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        #self.conv3 = nn.Conv2d(20, 20, kernel_size=5, stride=1, padding=1)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        \n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "         x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "         #x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "         x = x.view(x.size(0), 320)\n",
    "         x = F.relu(self.fc1(x))\n",
    "         x = F.dropout(x, training=self.training)\n",
    "         x = self.fc2(x)\n",
    "        \n",
    "         return F.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c91d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d02e90a",
   "metadata": {},
   "source": [
    "### Create a training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1a4cccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DigitalCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b92d109",
   "metadata": {},
   "source": [
    "### Create a training loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28cd294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch, (feature, target) in enumerate(loaders['train']):\n",
    "        feature, target = feature.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(feature)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 10 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch * len(feature)}/{len(loaders[\"train\"].dataset)} ({100. * batch / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec02e91",
   "metadata": {},
   "source": [
    "### Create a test loop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c1f92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss, correct =0, 0\n",
    "    with torch.inference_mode():\n",
    "        for feature, target in loaders['test']:\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "            output = model(feature)\n",
    "            test_loss += loss_fn(output, target).item()\n",
    "            test_pred = output.argmax(dim=1)\n",
    "            correct += test_pred.eq(target.view_as(test_pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(loaders['test'].dataset)\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loaders['test'].dataset)} ({100. * correct / len(loaders['test'].dataset):.0f}%\\n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da6570",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d451ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c881b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saheed\\AppData\\Local\\Temp\\ipykernel_13544\\1112552566.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\t2.300822\n",
      "Train Epoch: 0 [1000/60000 (2%)]\t2.301875\n",
      "Train Epoch: 0 [2000/60000 (3%)]\t2.302155\n",
      "Train Epoch: 0 [3000/60000 (5%)]\t2.303017\n",
      "Train Epoch: 0 [4000/60000 (7%)]\t2.300656\n",
      "Train Epoch: 0 [5000/60000 (8%)]\t2.300369\n",
      "Train Epoch: 0 [6000/60000 (10%)]\t2.300863\n",
      "Train Epoch: 0 [7000/60000 (12%)]\t2.299006\n",
      "Train Epoch: 0 [8000/60000 (13%)]\t2.299054\n",
      "Train Epoch: 0 [9000/60000 (15%)]\t2.295732\n",
      "Train Epoch: 0 [10000/60000 (17%)]\t2.298838\n",
      "Train Epoch: 0 [11000/60000 (18%)]\t2.293825\n",
      "Train Epoch: 0 [12000/60000 (20%)]\t2.294786\n",
      "Train Epoch: 0 [13000/60000 (22%)]\t2.289449\n",
      "Train Epoch: 0 [14000/60000 (23%)]\t2.281043\n",
      "Train Epoch: 0 [15000/60000 (25%)]\t2.273129\n",
      "Train Epoch: 0 [16000/60000 (27%)]\t2.283335\n",
      "Train Epoch: 0 [17000/60000 (28%)]\t2.247377\n",
      "Train Epoch: 0 [18000/60000 (30%)]\t2.255954\n",
      "Train Epoch: 0 [19000/60000 (32%)]\t2.212951\n",
      "Train Epoch: 0 [20000/60000 (33%)]\t2.240427\n",
      "Train Epoch: 0 [21000/60000 (35%)]\t2.219192\n",
      "Train Epoch: 0 [22000/60000 (37%)]\t2.195683\n",
      "Train Epoch: 0 [23000/60000 (38%)]\t2.177366\n",
      "Train Epoch: 0 [24000/60000 (40%)]\t2.121305\n",
      "Train Epoch: 0 [25000/60000 (42%)]\t2.183590\n",
      "Train Epoch: 0 [26000/60000 (43%)]\t2.181171\n",
      "Train Epoch: 0 [27000/60000 (45%)]\t2.141975\n",
      "Train Epoch: 0 [28000/60000 (47%)]\t2.152559\n",
      "Train Epoch: 0 [29000/60000 (48%)]\t2.129441\n",
      "Train Epoch: 0 [30000/60000 (50%)]\t2.047997\n",
      "Train Epoch: 0 [31000/60000 (52%)]\t2.116351\n",
      "Train Epoch: 0 [32000/60000 (53%)]\t2.058266\n",
      "Train Epoch: 0 [33000/60000 (55%)]\t2.085141\n",
      "Train Epoch: 0 [34000/60000 (57%)]\t1.981246\n",
      "Train Epoch: 0 [35000/60000 (58%)]\t2.054281\n",
      "Train Epoch: 0 [36000/60000 (60%)]\t2.066618\n",
      "Train Epoch: 0 [37000/60000 (62%)]\t2.078154\n",
      "Train Epoch: 0 [38000/60000 (63%)]\t1.956792\n",
      "Train Epoch: 0 [39000/60000 (65%)]\t1.975735\n",
      "Train Epoch: 0 [40000/60000 (67%)]\t2.048603\n",
      "Train Epoch: 0 [41000/60000 (68%)]\t1.982513\n",
      "Train Epoch: 0 [42000/60000 (70%)]\t2.007273\n",
      "Train Epoch: 0 [43000/60000 (72%)]\t1.994605\n",
      "Train Epoch: 0 [44000/60000 (73%)]\t1.916297\n",
      "Train Epoch: 0 [45000/60000 (75%)]\t1.856750\n",
      "Train Epoch: 0 [46000/60000 (77%)]\t1.948043\n",
      "Train Epoch: 0 [47000/60000 (78%)]\t1.980595\n",
      "Train Epoch: 0 [48000/60000 (80%)]\t1.930208\n",
      "Train Epoch: 0 [49000/60000 (82%)]\t1.913553\n",
      "Train Epoch: 0 [50000/60000 (83%)]\t1.939730\n",
      "Train Epoch: 0 [51000/60000 (85%)]\t1.908102\n",
      "Train Epoch: 0 [52000/60000 (87%)]\t1.905077\n",
      "Train Epoch: 0 [53000/60000 (88%)]\t1.971729\n",
      "Train Epoch: 0 [54000/60000 (90%)]\t1.871436\n",
      "Train Epoch: 0 [55000/60000 (92%)]\t1.912420\n",
      "Train Epoch: 0 [56000/60000 (93%)]\t1.860036\n",
      "Train Epoch: 0 [57000/60000 (95%)]\t1.900167\n",
      "Train Epoch: 0 [58000/60000 (97%)]\t1.954772\n",
      "Train Epoch: 0 [59000/60000 (98%)]\t1.820736\n",
      "\n",
      "Test set: Average loss: 0.0176, Accuracy 7327/10000 (73%\n",
      ")\n",
      "Train Epoch: 1 [0/60000 (0%)]\t1.857738\n",
      "Train Epoch: 1 [1000/60000 (2%)]\t1.903250\n",
      "Train Epoch: 1 [2000/60000 (3%)]\t1.808704\n",
      "Train Epoch: 1 [3000/60000 (5%)]\t1.784017\n",
      "Train Epoch: 1 [4000/60000 (7%)]\t1.821475\n",
      "Train Epoch: 1 [5000/60000 (8%)]\t1.866996\n",
      "Train Epoch: 1 [6000/60000 (10%)]\t1.879127\n",
      "Train Epoch: 1 [7000/60000 (12%)]\t1.889762\n",
      "Train Epoch: 1 [8000/60000 (13%)]\t1.860685\n",
      "Train Epoch: 1 [9000/60000 (15%)]\t1.869264\n",
      "Train Epoch: 1 [10000/60000 (17%)]\t1.764454\n",
      "Train Epoch: 1 [11000/60000 (18%)]\t1.806524\n",
      "Train Epoch: 1 [12000/60000 (20%)]\t1.770243\n",
      "Train Epoch: 1 [13000/60000 (22%)]\t1.803798\n",
      "Train Epoch: 1 [14000/60000 (23%)]\t1.825183\n",
      "Train Epoch: 1 [15000/60000 (25%)]\t1.812787\n",
      "Train Epoch: 1 [16000/60000 (27%)]\t1.792454\n",
      "Train Epoch: 1 [17000/60000 (28%)]\t1.792452\n",
      "Train Epoch: 1 [18000/60000 (30%)]\t1.827971\n",
      "Train Epoch: 1 [19000/60000 (32%)]\t1.823665\n",
      "Train Epoch: 1 [20000/60000 (33%)]\t1.794347\n",
      "Train Epoch: 1 [21000/60000 (35%)]\t1.741265\n",
      "Train Epoch: 1 [22000/60000 (37%)]\t1.808299\n",
      "Train Epoch: 1 [23000/60000 (38%)]\t1.818652\n",
      "Train Epoch: 1 [24000/60000 (40%)]\t1.829309\n",
      "Train Epoch: 1 [25000/60000 (42%)]\t1.845491\n",
      "Train Epoch: 1 [26000/60000 (43%)]\t1.855321\n",
      "Train Epoch: 1 [27000/60000 (45%)]\t1.802275\n",
      "Train Epoch: 1 [28000/60000 (47%)]\t1.818158\n",
      "Train Epoch: 1 [29000/60000 (48%)]\t1.740374\n",
      "Train Epoch: 1 [30000/60000 (50%)]\t1.756776\n",
      "Train Epoch: 1 [31000/60000 (52%)]\t1.745069\n",
      "Train Epoch: 1 [32000/60000 (53%)]\t1.764752\n",
      "Train Epoch: 1 [33000/60000 (55%)]\t1.773762\n",
      "Train Epoch: 1 [34000/60000 (57%)]\t1.782760\n",
      "Train Epoch: 1 [35000/60000 (58%)]\t1.717781\n",
      "Train Epoch: 1 [36000/60000 (60%)]\t1.744920\n",
      "Train Epoch: 1 [37000/60000 (62%)]\t1.745977\n",
      "Train Epoch: 1 [38000/60000 (63%)]\t1.786814\n",
      "Train Epoch: 1 [39000/60000 (65%)]\t1.769904\n",
      "Train Epoch: 1 [40000/60000 (67%)]\t1.739907\n",
      "Train Epoch: 1 [41000/60000 (68%)]\t1.844897\n",
      "Train Epoch: 1 [42000/60000 (70%)]\t1.813291\n",
      "Train Epoch: 1 [43000/60000 (72%)]\t1.806691\n",
      "Train Epoch: 1 [44000/60000 (73%)]\t1.795686\n",
      "Train Epoch: 1 [45000/60000 (75%)]\t1.710269\n",
      "Train Epoch: 1 [46000/60000 (77%)]\t1.692989\n",
      "Train Epoch: 1 [47000/60000 (78%)]\t1.731784\n",
      "Train Epoch: 1 [48000/60000 (80%)]\t1.726900\n",
      "Train Epoch: 1 [49000/60000 (82%)]\t1.735229\n",
      "Train Epoch: 1 [50000/60000 (83%)]\t1.749173\n",
      "Train Epoch: 1 [51000/60000 (85%)]\t1.779105\n",
      "Train Epoch: 1 [52000/60000 (87%)]\t1.686450\n",
      "Train Epoch: 1 [53000/60000 (88%)]\t1.715242\n",
      "Train Epoch: 1 [54000/60000 (90%)]\t1.661376\n",
      "Train Epoch: 1 [55000/60000 (92%)]\t1.733213\n",
      "Train Epoch: 1 [56000/60000 (93%)]\t1.746845\n",
      "Train Epoch: 1 [57000/60000 (95%)]\t1.709516\n",
      "Train Epoch: 1 [58000/60000 (97%)]\t1.718125\n",
      "Train Epoch: 1 [59000/60000 (98%)]\t1.714257\n",
      "\n",
      "Test set: Average loss: 0.0163, Accuracy 8530/10000 (85%\n",
      ")\n",
      "Train Epoch: 2 [0/60000 (0%)]\t1.813000\n",
      "Train Epoch: 2 [1000/60000 (2%)]\t1.756823\n",
      "Train Epoch: 2 [2000/60000 (3%)]\t1.725341\n",
      "Train Epoch: 2 [3000/60000 (5%)]\t1.731630\n",
      "Train Epoch: 2 [4000/60000 (7%)]\t1.712806\n",
      "Train Epoch: 2 [5000/60000 (8%)]\t1.757558\n",
      "Train Epoch: 2 [6000/60000 (10%)]\t1.737893\n",
      "Train Epoch: 2 [7000/60000 (12%)]\t1.740375\n",
      "Train Epoch: 2 [8000/60000 (13%)]\t1.707143\n",
      "Train Epoch: 2 [9000/60000 (15%)]\t1.726479\n",
      "Train Epoch: 2 [10000/60000 (17%)]\t1.753564\n",
      "Train Epoch: 2 [11000/60000 (18%)]\t1.698134\n",
      "Train Epoch: 2 [12000/60000 (20%)]\t1.712984\n",
      "Train Epoch: 2 [13000/60000 (22%)]\t1.749559\n",
      "Train Epoch: 2 [14000/60000 (23%)]\t1.750322\n",
      "Train Epoch: 2 [15000/60000 (25%)]\t1.795660\n",
      "Train Epoch: 2 [16000/60000 (27%)]\t1.761758\n",
      "Train Epoch: 2 [17000/60000 (28%)]\t1.721946\n",
      "Train Epoch: 2 [18000/60000 (30%)]\t1.689396\n",
      "Train Epoch: 2 [19000/60000 (32%)]\t1.660191\n",
      "Train Epoch: 2 [20000/60000 (33%)]\t1.662539\n",
      "Train Epoch: 2 [21000/60000 (35%)]\t1.762485\n",
      "Train Epoch: 2 [22000/60000 (37%)]\t1.661494\n",
      "Train Epoch: 2 [23000/60000 (38%)]\t1.663327\n",
      "Train Epoch: 2 [24000/60000 (40%)]\t1.729007\n",
      "Train Epoch: 2 [25000/60000 (42%)]\t1.673335\n",
      "Train Epoch: 2 [26000/60000 (43%)]\t1.711441\n",
      "Train Epoch: 2 [27000/60000 (45%)]\t1.713648\n",
      "Train Epoch: 2 [28000/60000 (47%)]\t1.731092\n",
      "Train Epoch: 2 [29000/60000 (48%)]\t1.733466\n",
      "Train Epoch: 2 [30000/60000 (50%)]\t1.723800\n",
      "Train Epoch: 2 [31000/60000 (52%)]\t1.698543\n",
      "Train Epoch: 2 [32000/60000 (53%)]\t1.737827\n",
      "Train Epoch: 2 [33000/60000 (55%)]\t1.752091\n",
      "Train Epoch: 2 [34000/60000 (57%)]\t1.689173\n",
      "Train Epoch: 2 [35000/60000 (58%)]\t1.695683\n",
      "Train Epoch: 2 [36000/60000 (60%)]\t1.680089\n",
      "Train Epoch: 2 [37000/60000 (62%)]\t1.751354\n",
      "Train Epoch: 2 [38000/60000 (63%)]\t1.710358\n",
      "Train Epoch: 2 [39000/60000 (65%)]\t1.696198\n",
      "Train Epoch: 2 [40000/60000 (67%)]\t1.756101\n",
      "Train Epoch: 2 [41000/60000 (68%)]\t1.680482\n",
      "Train Epoch: 2 [42000/60000 (70%)]\t1.662428\n",
      "Train Epoch: 2 [43000/60000 (72%)]\t1.693044\n",
      "Train Epoch: 2 [44000/60000 (73%)]\t1.679098\n",
      "Train Epoch: 2 [45000/60000 (75%)]\t1.677008\n",
      "Train Epoch: 2 [46000/60000 (77%)]\t1.673878\n",
      "Train Epoch: 2 [47000/60000 (78%)]\t1.733114\n",
      "Train Epoch: 2 [48000/60000 (80%)]\t1.690926\n",
      "Train Epoch: 2 [49000/60000 (82%)]\t1.743001\n",
      "Train Epoch: 2 [50000/60000 (83%)]\t1.722461\n",
      "Train Epoch: 2 [51000/60000 (85%)]\t1.777613\n",
      "Train Epoch: 2 [52000/60000 (87%)]\t1.689590\n",
      "Train Epoch: 2 [53000/60000 (88%)]\t1.668809\n",
      "Train Epoch: 2 [54000/60000 (90%)]\t1.686640\n",
      "Train Epoch: 2 [55000/60000 (92%)]\t1.636827\n",
      "Train Epoch: 2 [56000/60000 (93%)]\t1.734127\n",
      "Train Epoch: 2 [57000/60000 (95%)]\t1.671300\n",
      "Train Epoch: 2 [58000/60000 (97%)]\t1.651356\n",
      "Train Epoch: 2 [59000/60000 (98%)]\t1.653417\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy 8914/10000 (89%\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46eee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0 - zero', '1 - one', '2 - two', '3 - three', '4 - four', '5 - five', '6 - six', '7 - seven', '8 - eight', '9 - nine']\n"
     ]
    }
   ],
   "source": [
    "lst_digits = []\n",
    "for i in train_data.classes:\n",
    "    lst_digits.append(i)\n",
    "print(lst_digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478daadc",
   "metadata": {},
   "source": [
    "### Predict and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4df3e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please Enter the index number to predict its digit: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saheed\\AppData\\Local\\Temp\\ipykernel_13544\\1112552566.py:21: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 4\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZd0lEQVR4nO3df2jU9x3H8dfVH+ePXY6FmNylxph1SrfGOfwxNbT+KPNmtolWHdqWETdw7fwBIS1lzg2zbpgiGPpHpmNlc8qqFTbrBKU2QxMtzpEGpdaJpDXWDA3BzN7FaOPUz/4IHjuNP77nXd655PmAL3jf+378fvz2q89+c3ff8znnnAAAMPCY9QQAAAMXEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGYGW0/gTrdu3dKFCxcUCATk8/mspwMA8Mg5p46ODuXn5+uxx+5/rdPnInThwgUVFBRYTwMA8IhaWlo0evTo+27T534cFwgErKcAAEiBh/n3PG0R2rx5s4qKijRs2DBNnjxZR44ceahx/AgOAPqHh/n3PC0R2rVrl8rLy7Vu3TodP35czzzzjEpLS3X+/Pl07A4AkKF86biL9rRp0zRp0iRt2bIlvu5rX/uaFi5cqKqqqvuOjcViCgaDqZ4SAKCXRaNRZWVl3XeblF8JXb9+XY2NjYpEIgnrI5GIjh49etf2XV1disViCQsAYGBIeYQuXbqkmzdvKi8vL2F9Xl6eWltb79q+qqpKwWAwvvDOOAAYONL2xoQ7X5ByzvX4ItXatWsVjUbjS0tLS7qmBADoY1L+OaGcnBwNGjTorquetra2u66OJMnv98vv96d6GgCADJDyK6GhQ4dq8uTJqq2tTVhfW1urkpKSVO8OAJDB0nLHhIqKCv3whz/UlClTNGPGDP3+97/X+fPn9fLLL6djdwCADJWWCC1dulTt7e16/fXXdfHiRRUXF2v//v0qLCxMx+4AABkqLZ8TehR8TggA+geTzwkBAPCwiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADODrScAPMikSZM8j9m9e3dS+xo7dmxS45CcSCTieczp06c9j2lpafE8Br2DKyEAgBkiBAAwk/IIVVZWyufzJSyhUCjVuwEA9ANpeU3oqaee0t///vf440GDBqVjNwCADJeWCA0ePJirHwDAA6XlNaGmpibl5+erqKhIy5Yt09mzZ++5bVdXl2KxWMICABgYUh6hadOmafv27Tpw4IDeeusttba2qqSkRO3t7T1uX1VVpWAwGF8KCgpSPSUAQB+V8giVlpZq8eLFmjBhgr797W9r3759kqRt27b1uP3atWsVjUbjC+/nB4CBI+0fVh05cqQmTJigpqamHp/3+/3y+/3pngYAoA9K++eEurq6dPr0aYXD4XTvCgCQYVIeoVdffVX19fVqbm7WP//5Ty1ZskSxWExlZWWp3hUAIMOl/Mdx//73v/X888/r0qVLGjVqlKZPn65jx46psLAw1bsCAGS4lEfonXfeSfVviQHuO9/5jucxvM6YGebPn+95zI9//GPPY5YtW+Z5DHoH944DAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMyk/UvtgP83eLD3U+673/1uGmaCvqCxsdHzmIqKCs9jRo4c6XmMJHV2diY1Dg+PKyEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4S7a6FVz5szxPGbGjBmex2zcuNHzGPS+L3/5y57HfP3rX/c8ZsSIEZ7HSNxFuzdwJQQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmOEGpkhacXGx5zE7d+70PObTTz/1PGbDhg2ex6D3LViwwHoKMMaVEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghhuYImm/+MUvPI8ZOXKk5zHz5s3zPObKlSuex+DRZGdnex4za9Ysz2Nu3brleQz6Lq6EAABmiBAAwIznCB0+fFjz589Xfn6+fD6f9uzZk/C8c06VlZXKz8/X8OHDNXv2bJ06dSpV8wUA9COeI9TZ2amJEyeqpqamx+c3btyo6upq1dTUqKGhQaFQSHPnzlVHR8cjTxYA0L94fmNCaWmpSktLe3zOOac333xT69at06JFiyRJ27ZtU15ennbs2KGXXnrp0WYLAOhXUvqaUHNzs1pbWxWJROLr/H6/Zs2apaNHj/Y4pqurS7FYLGEBAAwMKY1Qa2urJCkvLy9hfV5eXvy5O1VVVSkYDMaXgoKCVE4JANCHpeXdcT6fL+Gxc+6udbetXbtW0Wg0vrS0tKRjSgCAPiilH1YNhUKSuq+IwuFwfH1bW9tdV0e3+f1++f3+VE4DAJAhUnolVFRUpFAopNra2vi669evq76+XiUlJancFQCgH/B8JXTlyhV98skn8cfNzc06ceKEsrOzNWbMGJWXl2vDhg0aN26cxo0bpw0bNmjEiBF64YUXUjpxAEDm8xyhDz/8UHPmzIk/rqiokCSVlZXpT3/6k1577TVdu3ZNK1eu1OXLlzVt2jS9//77CgQCqZs1AKBf8DnnnPUk/l8sFlMwGLSexoCyZMmSpMb98Y9/9Dzms88+8zxmwoQJnseg923atMnzmPLycs9j6urqPI9J5ia4kvTf//43qXHoFo1GlZWVdd9tuHccAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzKT0m1WRmX7wgx8kNW7EiBGex2zevDmpfaF3jR071vOYF1980fOYmzdveh7zm9/8xvMY7obdd3ElBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4Qam/UwwGPQ8Zvr06WmYSc+2bNnSa/tC8n7yk594HpOTk+N5zOnTpz2POXTokOcx6Lu4EgIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzHAD037G7/d7HvP4448nta+dO3cmNQ593xNPPNEr+/n44497ZT/ou7gSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcAPTfqajo8PzmBMnTiS1r2984xuex2RnZ3se85///MfzGHTLzc1NatySJUtSPJOeffDBB72yH/RdXAkBAMwQIQCAGc8ROnz4sObPn6/8/Hz5fD7t2bMn4fnly5fL5/MlLNOnT0/VfAEA/YjnCHV2dmrixImqqam55zbz5s3TxYsX48v+/fsfaZIAgP7J8xsTSktLVVpaet9t/H6/QqFQ0pMCAAwMaXlNqK6uTrm5uRo/frxWrFihtra2e27b1dWlWCyWsAAABoaUR6i0tFRvv/22Dh48qE2bNqmhoUHPPvusurq6ety+qqpKwWAwvhQUFKR6SgCAPirlnxNaunRp/NfFxcWaMmWKCgsLtW/fPi1atOiu7deuXauKior441gsRogAYIBI+4dVw+GwCgsL1dTU1OPzfr9ffr8/3dMAAPRBaf+cUHt7u1paWhQOh9O9KwBAhvF8JXTlyhV98skn8cfNzc06ceKEsrOzlZ2drcrKSi1evFjhcFjnzp3Tz3/+c+Xk5Oi5555L6cQBAJnPc4Q+/PBDzZkzJ/749us5ZWVl2rJli06ePKnt27fr888/Vzgc1pw5c7Rr1y4FAoHUzRoA0C94jtDs2bPlnLvn8wcOHHikCeHRXLt2zfOYTz/9NKl9LV682POYffv2eR5TXV3teUxfV1xc7HnMV77yFc9jxo4d63mMpPv+HU+lW7du9cp+0Hdx7zgAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY8bneul3uQ4rFYgoGg9bTGFCefPLJpMa9/vrrnsd873vf8zymP37z7qVLlzyPSeavak5OjucxkuTz+ZIa51UyX/GSzJ3iYSMajSorK+u+23AlBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCY4Qam6FXf/OY3PY/56le/mvqJGPvLX/7SK/vZtm1bUuNefPHFFM+kZ4MHD+6V/cAGNzAFAPRpRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZ7h6IXnXixIleGYNuZ8+etZ7CfRUXF3se8/HHH6dhJrDClRAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYbmAL9mM/n69VxXnEzUnAlBAAwQ4QAAGY8RaiqqkpTp05VIBBQbm6uFi5cqDNnziRs45xTZWWl8vPzNXz4cM2ePVunTp1K6aQBAP2DpwjV19dr1apVOnbsmGpra3Xjxg1FIhF1dnbGt9m4caOqq6tVU1OjhoYGhUIhzZ07Vx0dHSmfPAAgs3l6Y8J7772X8Hjr1q3Kzc1VY2OjZs6cKeec3nzzTa1bt06LFi2SJG3btk15eXnasWOHXnrppdTNHACQ8R7pNaFoNCpJys7OliQ1NzertbVVkUgkvo3f79esWbN09OjRHn+Prq4uxWKxhAUAMDAkHSHnnCoqKvT000/Hvye+tbVVkpSXl5ewbV5eXvy5O1VVVSkYDMaXgoKCZKcEAMgwSUdo9erV+uijj7Rz5867nrvzMwbOuXt+7mDt2rWKRqPxpaWlJdkpAQAyTFIfVl2zZo327t2rw4cPa/To0fH1oVBIUvcVUTgcjq9va2u76+roNr/fL7/fn8w0AAAZztOVkHNOq1ev1u7du3Xw4EEVFRUlPF9UVKRQKKTa2tr4uuvXr6u+vl4lJSWpmTEAoN/wdCW0atUq7dixQ3/7298UCATir/MEg0ENHz5cPp9P5eXl2rBhg8aNG6dx48Zpw4YNGjFihF544YW0/AEAAJnLU4S2bNkiSZo9e3bC+q1bt2r58uWSpNdee03Xrl3TypUrdfnyZU2bNk3vv/++AoFASiYMAOg/PEXIOffAbXw+nyorK1VZWZnsnACkyMP8nU3lOMAr7h0HADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0l9syqAzDBs2LBe29e1a9d6bV/oP7gSAgCYIUIAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMcANToB/70Y9+lNS4zz//3POYX//610ntCwMbV0IAADNECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBluYAr0Yw0NDUmNq66u9jzm0KFDSe0LAxtXQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMwQIQCAGZ9zzllP4v/FYjEFg0HraQAAHlE0GlVWVtZ9t+FKCABghggBAMx4ilBVVZWmTp2qQCCg3NxcLVy4UGfOnEnYZvny5fL5fAnL9OnTUzppAED/4ClC9fX1WrVqlY4dO6ba2lrduHFDkUhEnZ2dCdvNmzdPFy9ejC/79+9P6aQBAP2Dp29Wfe+99xIeb926Vbm5uWpsbNTMmTPj6/1+v0KhUGpmCADotx7pNaFoNCpJys7OTlhfV1en3NxcjR8/XitWrFBbW9s9f4+uri7FYrGEBQAwMCT9Fm3nnBYsWKDLly/ryJEj8fW7du3Sl770JRUWFqq5uVm//OUvdePGDTU2Nsrv99/1+1RWVupXv/pV8n8CAECf9DBv0ZZL0sqVK11hYaFraWm573YXLlxwQ4YMcX/96197fP6LL75w0Wg0vrS0tDhJLCwsLCwZvkSj0Qe2xNNrQretWbNGe/fu1eHDhzV69Oj7bhsOh1VYWKimpqYen/f7/T1eIQEA+j9PEXLOac2aNXr33XdVV1enoqKiB45pb29XS0uLwuFw0pMEAPRPnt6YsGrVKv35z3/Wjh07FAgE1NraqtbWVl27dk2SdOXKFb366qv6xz/+oXPnzqmurk7z589XTk6OnnvuubT8AQAAGczL60C6x8/9tm7d6pxz7urVqy4SibhRo0a5IUOGuDFjxriysjJ3/vz5h95HNBo1/zkmCwsLC8ujLw/zmhA3MAUApAU3MAUA9GlECABghggBAMwQIQCAGSIEADBDhAAAZogQAMAMEQIAmCFCAAAzRAgAYIYIAQDMECEAgBkiBAAwQ4QAAGaIEADADBECAJghQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADN9LkLOOespAABS4GH+Pe9zEero6LCeAgAgBR7m33Of62OXHrdu3dKFCxcUCATk8/kSnovFYiooKFBLS4uysrKMZmiP49CN49CN49CN49CtLxwH55w6OjqUn5+vxx67/7XO4F6a00N77LHHNHr06Ptuk5WVNaBPsts4Dt04Dt04Dt04Dt2sj0MwGHyo7frcj+MAAAMHEQIAmMmoCPn9fq1fv15+v996KqY4Dt04Dt04Dt04Dt0y7Tj0uTcmAAAGjoy6EgIA9C9ECABghggBAMwQIQCAmYyK0ObNm1VUVKRhw4Zp8uTJOnLkiPWUelVlZaV8Pl/CEgqFrKeVdocPH9b8+fOVn58vn8+nPXv2JDzvnFNlZaXy8/M1fPhwzZ49W6dOnbKZbBo96DgsX778rvNj+vTpNpNNk6qqKk2dOlWBQEC5ublauHChzpw5k7DNQDgfHuY4ZMr5kDER2rVrl8rLy7Vu3TodP35czzzzjEpLS3X+/HnrqfWqp556ShcvXowvJ0+etJ5S2nV2dmrixImqqanp8fmNGzequrpaNTU1amhoUCgU0ty5c/vdfQgfdBwkad68eQnnx/79+3txhulXX1+vVatW6dixY6qtrdWNGzcUiUTU2dkZ32YgnA8PcxykDDkfXIb41re+5V5++eWEdU8++aT72c9+ZjSj3rd+/Xo3ceJE62mYkuTefffd+ONbt265UCjk3njjjfi6L774wgWDQfe73/3OYIa9487j4JxzZWVlbsGCBSbzsdLW1uYkufr6eufcwD0f7jwOzmXO+ZARV0LXr19XY2OjIpFIwvpIJKKjR48azcpGU1OT8vPzVVRUpGXLluns2bPWUzLV3Nys1tbWhHPD7/dr1qxZA+7ckKS6ujrl5uZq/PjxWrFihdra2qynlFbRaFSSlJ2dLWngng93HofbMuF8yIgIXbp0STdv3lReXl7C+ry8PLW2thrNqvdNmzZN27dv14EDB/TWW2+ptbVVJSUlam9vt56amdv//Qf6uSFJpaWlevvtt3Xw4EFt2rRJDQ0NevbZZ9XV1WU9tbRwzqmiokJPP/20iouLJQ3M86Gn4yBlzvnQ5+6ifT93frWDc+6udf1ZaWlp/NcTJkzQjBkz9MQTT2jbtm2qqKgwnJm9gX5uSNLSpUvjvy4uLtaUKVNUWFioffv2adGiRYYzS4/Vq1fro48+0gcffHDXcwPpfLjXcciU8yEjroRycnI0aNCgu/5Ppq2t7a7/4xlIRo4cqQkTJqipqcl6KmZuvzuQc+Nu4XBYhYWF/fL8WLNmjfbu3atDhw4lfPXLQDsf7nUcetJXz4eMiNDQoUM1efJk1dbWJqyvra1VSUmJ0azsdXV16fTp0wqHw9ZTMVNUVKRQKJRwbly/fl319fUD+tyQpPb2drW0tPSr88M5p9WrV2v37t06ePCgioqKEp4fKOfDg45DT/rs+WD4pghP3nnnHTdkyBD3hz/8wf3rX/9y5eXlbuTIke7cuXPWU+s1r7zyiqurq3Nnz551x44dc9///vddIBDo98ego6PDHT9+3B0/ftxJctXV1e748ePus88+c84598Ybb7hgMOh2797tTp486Z5//nkXDoddLBYznnlq3e84dHR0uFdeecUdPXrUNTc3u0OHDrkZM2a4xx9/vF8dh5/+9KcuGAy6uro6d/Hixfhy9erV+DYD4Xx40HHIpPMhYyLknHO//e1vXWFhoRs6dKibNGlSwtsRB4KlS5e6cDjshgwZ4vLz892iRYvcqVOnrKeVdocOHXKS7lrKysqcc91vy12/fr0LhULO7/e7mTNnupMnT9pOOg3udxyuXr3qIpGIGzVqlBsyZIgbM2aMKysrc+fPn7eedkr19OeX5LZu3RrfZiCcDw86Dpl0PvBVDgAAMxnxmhAAoH8iQgAAM0QIAGCGCAEAzBAhAIAZIgQAMEOEAABmiBAAwAwRAgCYIUIAADNECABghggBAMz8D6AVsAIxUXIvAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "index_num = int(input('Please Enter the index number to predict its digit: '))\n",
    "feature, target = test_data[index_num]\n",
    "feature = feature.unsqueeze(0).to(device)\n",
    "output = model(feature)\n",
    "prediction = output.argmax(dim=1).item()\n",
    "print('Prediction: {}'.format(prediction))\n",
    "image = feature.squeeze(0).squeeze(0).cpu().numpy()\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff41d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
